{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolor\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import Phylo\n",
    "import seaborn as sns\n",
    "from scipy.stats import t, ttest_1samp, wilcoxon, mannwhitneyu, ttest_rel, zscore, spearmanr\n",
    "import json\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn import linear_model\n",
    "import re\n",
    "from matplotlib.colors import ListedColormap\n",
    "import networkx as nx\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['font.family']       = 'Arial'\n",
    "matplotlib.rcParams['font.sans-serif']   = [\"Arial\",\"DejaVu Sans\",\"Lucida Grande\",\"Verdana\"]\n",
    "matplotlib.rcParams['figure.figsize']    = [4,3]\n",
    "matplotlib.rcParams['font.size']         = 10\n",
    "matplotlib.rcParams[\"axes.labelcolor\"]   = \"#000000\"\n",
    "matplotlib.rcParams[\"axes.linewidth\"]    = 1.0 \n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 1.0\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 1.0\n",
    "cmap1 = plt.cm.tab20\n",
    "cmap2 = plt.cm.Set3  \n",
    "#plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151\")\n",
    "\n",
    "for dir in [\"figures\", \"tables\", \"networks\"]:\n",
    "    try:\n",
    "        os.mkdir(dir)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classess of KOs\n",
    "\n",
    "df_path_ko = pd.read_table(\"tables/path_ko.txt\", names = ['Pathway', 'KO'])\n",
    "df_rn_ko = pd.read_table(\"tables/rn_ko.txt\", names = ['Reaction','KO'])\n",
    "df_md_ko = pd.read_table(\"tables/md_ko.txt\", names = ['Module','KO'])\n",
    "df_path_md = pd.read_table(\"tables/path_md.txt\", names = ['Pathway','Module'])\n",
    "ontology = json.load(open(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/json/ko00001.json\"))\n",
    "\n",
    "ontology_tree = Phylo.BaseTree.Tree(Phylo.BaseTree.Clade(name=ontology['name']))\n",
    "root_clade    = Phylo.BaseTree.Clade(name=ontology['name'])\n",
    "stack = [(ontology, root_clade)]\n",
    "\n",
    "while len(stack) > 0:\n",
    "    term, clade = stack.pop()\n",
    "    if ('children' in term.keys()):\n",
    "        for child in term['children']:\n",
    "            child_clade = Phylo.BaseTree.Clade(name = child['name'])\n",
    "            clade.clades.append(child_clade)\n",
    "            stack.append((child, child_clade))\n",
    "\n",
    "ontology_tree = Phylo.BaseTree.Tree(root_clade)\n",
    "\n",
    "list_category_ko = []\n",
    "for clade in ontology_tree.clade.clades[0].clades:\n",
    "    for tip in clade.get_terminals():\n",
    "        KO = tip.name.split()[0]\n",
    "        if (KO[0] == 'K'):\n",
    "            list_category_ko.append([clade.name, KO])\n",
    "df_category_ko = pd.DataFrame(list_category_ko, columns = ['category', 'KO'])\n",
    "st_category_ko = []\n",
    "for clade in ontology_tree.clade.clades[0].clades:\n",
    "    for tip in clade.get_terminals():\n",
    "        KO = tip.name.split()[0]\n",
    "        if (KO[0] == 'K'):\n",
    "            list_category_ko.append([clade.name, KO])\n",
    "df_category_ko = pd.DataFrame(list_category_ko, columns = ['category', 'KO'])\n",
    "df_category_ko = df_category_ko[~df_category_ko.duplicated()]\n",
    "\n",
    "df_ko_count = pd.DataFrame(df_category_ko.KO.value_counts())\n",
    "set_ko_with_unique_category = set(df_ko_count[df_ko_count['KO']==1].index)\n",
    "df_category_ko['unique'] = [(ko in set_ko_with_unique_category) for ko in df_category_ko.KO]\n",
    "df_uniquecategory_ko = df_category_ko[df_category_ko['unique']]\n",
    "\n",
    "# color of function categories\n",
    "\n",
    "colors = ['#66C2A5', '#FC8D62', '#8DA0CB', '#E78AC3', '#555555', '#FC8D62', '#8DA0CB', '#E78AC3', '#66C2A5', '#FC8D62', '#000000']\n",
    "\n",
    "cm_name = 'Set3' # B->G->R\n",
    "cm = plt.get_cmap(cm_name)\n",
    "\n",
    "df_category_ko_module = pd.merge(df_category_ko, df_md_ko, on = 'KO')\n",
    "df_category_ko_module['Nko'] = 1\n",
    "df_category_module_count = df_category_ko_module.groupby(['category', 'Module'], as_index = False).sum()\n",
    "df_maxcategory_module = df_category_module_count.loc[df_category_module_count.groupby('Module')['Nko'].idxmax(),:].sort_values('category')\n",
    "df_maxcategory_module = df_maxcategory_module.reset_index().loc[:, ['category', 'Module']]\n",
    "df_category_color = pd.DataFrame([[category, i] for i, category in enumerate(df_maxcategory_module.category.unique())], columns = [\"category\", 'category_id'])\n",
    "df_category_color['color'] = [mcolor.rgb2hex(cm(i)) for i in df_category_color['category_id']]\n",
    "#df_category_color\n",
    "\n",
    "df_category_ko_pathway = pd.merge(df_category_ko, df_path_ko, on = 'KO')\n",
    "df_category_ko_pathway['Nko'] = 1\n",
    "df_category_pathway_count = df_category_ko_pathway.groupby(['category', 'Pathway'], as_index = False).sum()\n",
    "df_maxcategory_pathway = df_category_pathway_count.loc[df_category_pathway_count.groupby('Pathway')['Nko'].idxmax(),:].sort_values('category')\n",
    "df_maxcategory_pathway = df_maxcategory_pathway.reset_index().loc[:, ['category', 'Pathway']]\n",
    "df_maxcategory_pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize AUC of cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = 'mlgtdb'\n",
    "acr  = 'MPPA'\n",
    "\n",
    "for tree, acr in [('mlgtdb', 'MPPA'), ('mlgtdb', 'DOWNPASS'), ('nj', 'MPPA'), ('nj', 'DOWNPASS')]:\n",
    "    df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.\"+tree+\".\"+acr+\".txt\", names = ['KO', 'target', 'method', 'auc'])\n",
    "    df_auc = df_auc_raw.groupby(['KO', 'target', 'method'], as_index = False).mean()\n",
    "\n",
    "    # visualize\n",
    "    #df_auc_ext = df_auc[df_auc['target'] == target]\n",
    "    fig = plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    sns.violinplot(data = df_auc, x = 'method', y = 'auc', hue = 'target', linewidth=0.5, order = ['RF','LR'], palette = ['#FFFFFF', '#FFFFFF'])\n",
    "    sns.stripplot (data = df_auc, x = 'method', y = 'auc', hue = 'target', linewidth=0,   order = ['RF','LR'], palette = ['#9FA6F1', '#E1BB63'], size = 1, alpha=.3,jitter=0.3, dodge=True)\n",
    "    ax.set_ylabel(\"AUC\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_title(tree+\" \"+acr)\n",
    "    ax.axhline(0.5, linewidth = 1, alpha = 0.5, color = '#555555')\n",
    "    plt.savefig(\"figures/NK_M0151_crossvalidation_\"+tree+\"_\"+acr+\".pdf\",bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # test if average AUC is 0.5\n",
    "    for method in ['LR', 'RF']:\n",
    "        for target in ['gain', 'loss']:\n",
    "            print(tree, acr, target, method, ttest_1samp(df_auc[(df_auc['method'] == method) & (df_auc['target'] == target)]['auc'], 0.5).pvalue)\n",
    "\n",
    "    # test if AUC of LR and RF is equal\n",
    "    for target in ['gain', 'loss']:\n",
    "        df_auc_comp = pd.merge(df_auc[(df_auc['method'] == 'LR') & (df_auc['target'] == target)], df_auc[(df_auc['method'] == 'RF') & (df_auc['target'] == target)], on = 'KO')\n",
    "        print(tree, acr, target, 'LR', 'RF', wilcoxon(df_auc_comp['auc_x'], df_auc_comp['auc_y']).pvalue)\n",
    "\n",
    "    # test if AUC of gain and loss is equal\n",
    "    for method in ['LR', 'RF']:\n",
    "        df_auc_gain = df_auc[(df_auc['method'] == method) & (df_auc['target'] == 'gain')]\n",
    "        df_auc_loss = df_auc[(df_auc['method'] == method) & (df_auc['target'] == 'loss')]\n",
    "        print(tree, acr, method, 'gain', 'loss', mannwhitneyu(df_auc_gain.auc, df_auc_loss.auc).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, acr = 'mlgtdb', 'MPPA'\n",
    "df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.\"+tree+\".\"+acr+\".txt\", names = ['KO', 'target', 'method', 'auc'])\n",
    "df_auc = df_auc_raw.groupby(['KO', 'target', 'method'], as_index = False).mean()\n",
    "\n",
    "df_auc.value_counts([\"target\", \"method\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation between gain predictability and loss predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Relation between gain predictability and loss predictability\n",
    "tree = 'mlgtdb'\n",
    "acr  = 'MPPA'\n",
    "\n",
    "for tree, acr in [('mlgtdb', 'MPPA'), ('mlgtdb', 'DOWNPASS'), ('nj', 'MPPA'), ('nj', 'DOWNPASS')]:\n",
    "    df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.\"+tree+\".\"+acr+\".txt\", names = ['KO', 'target', 'method', 'auc'])\n",
    "    df_auc = df_auc_raw.groupby(['KO', 'target', 'method'], as_index = False).mean()\n",
    "\n",
    "    for method in ['LR', 'RF']:\n",
    "        df_auc_gain_loss = pd.merge(df_auc[(df_auc['method']==method) & (df_auc['target']=='gain')], df_auc[(df_auc['method']==method) & (df_auc['target']=='loss')], on = 'KO')\n",
    "\n",
    "        x = df_auc_gain_loss.auc_x\n",
    "        y = df_auc_gain_loss.auc_y\n",
    "        xy = np.vstack([x,y])\n",
    "        z = gaussian_kde(xy)(xy)\n",
    "        idx = z.argsort()\n",
    "        x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "        clf = linear_model.LinearRegression()\n",
    "        x2 = [[x_] for x_ in x]\n",
    "        clf.fit(x2, y)\n",
    "\n",
    "        print(tree+\" \"+acr+\" \"+method)\n",
    "        print(\"correlation coeff= \", clf.coef_)\n",
    "        print(\"intercept= \", clf.intercept_)\n",
    "        print(\"score= \", clf.score(x2, y))\n",
    "        print(\"Spearman r = \",spearmanr(x2, y))\n",
    "\n",
    "        fig = plt.figure(figsize=(2,2))\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        #ax.plot([-200, 500], [-200, 500], 'k-', lw=0.5, alpha = 0.5, color = '#555555')\n",
    "        ax.scatter(x = x, y = y, c = z, s = 1, alpha = 0.5)\n",
    "\n",
    "        # plot a regression line\n",
    "        ax.set_title('Linear regression')\n",
    "        ax.plot(x2, clf.predict(x2), color = '#000000', alpha =0.5)\n",
    "\n",
    "\n",
    "        ax.set_xlim(-0.01,1.01)\n",
    "        ax.set_ylim(-0.01,1.01)\n",
    "        #ax.set_xscale(\"log\")\n",
    "        #ax.set_yscale(\"log\")\n",
    "        ax.set_xlabel(\"AUC of gain\")\n",
    "        ax.set_ylabel(\"AUC of loss\")\n",
    "        #ax.set_xticks([0,100,200,300])\n",
    "        ax.set_title(tree+\" \"+acr+\" \"+method)\n",
    "        plt.savefig(\"figures/NK_M0151_AUCgain_AUCloss_\"+tree+\"_\"+acr+\"_\"+method+\".pdf\",bbox_inches = 'tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation between AUC and number of gai/losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = \"mlgtdb\"\n",
    "acr = \"MPPA\"\n",
    "\n",
    "df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.\"+tree+\".\"+acr+\".txt\", names = ['KO', 'target', 'method', 'auc'])\n",
    "df_auc = df_auc_raw.groupby(['KO', 'target', 'method'], as_index = False).mean()\n",
    "    \n",
    "df_ko_Ngain_Nloss = pd.read_table(\"../NK_M0150/table/ko_Ngain_Nloss.mlgtdb_MPPA.txt\")\n",
    "df_ko_auc_Ngain_Nloss = pd.merge(df_auc, df_ko_Ngain_Nloss, on = \"KO\", how = \"left\")\n",
    "\n",
    "target = \"gain\"\n",
    "pred_method = \"RF\"\n",
    "\n",
    "for target in [\"gain\", \"loss\"]:\n",
    "    for method in [\"LR\", \"RF\"]:\n",
    "\n",
    "        df_ko_auc_Ngain_Nloss_ext = df_ko_auc_Ngain_Nloss[(df_ko_auc_Ngain_Nloss[\"target\"] == target) & (df_ko_auc_Ngain_Nloss[\"method\"] == method)]\n",
    "        x = np.array(df_ko_auc_Ngain_Nloss_ext[\"N\"+target])\n",
    "\n",
    "        #for target, x in [\"gain\", \n",
    "\n",
    "        y = np.array(df_ko_auc_Ngain_Nloss_ext.auc)\n",
    "        xy = np.vstack([x,y])\n",
    "        z = gaussian_kde(xy)(xy)\n",
    "        idx = z.argsort()\n",
    "        x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "        clf = linear_model.LinearRegression()\n",
    "        x2 = [[x_] for x_ in x]\n",
    "        clf.fit(x2, y)\n",
    "\n",
    "        print(target+\" \"+method)\n",
    "        print(\"回帰係数= \", clf.coef_)\n",
    "        print(\"切片= \", clf.intercept_)\n",
    "        print(\"決定係数= \", clf.score(x2, y))\n",
    "        print(\"Spearman r = \",spearmanr(x2, y))\n",
    "\n",
    "        fig = plt.figure(figsize=(2,2))\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        #ax.plot([-200, 500], [-200, 500], 'k-', lw=0.5, alpha = 0.5, color = '#555555')\n",
    "        ax.scatter(x = x, y = y, c = z, s = 1, alpha = 0.5)\n",
    "\n",
    "        # 回帰直線\n",
    "        #ax.set_title('Linear regression')\n",
    "        #ax.plot(x2, clf.predict(x2), color = '#000000', alpha =0.5)\n",
    "\n",
    "\n",
    "        #ax.set_xlim(-0.01,1.01)\n",
    "        ax.set_ylim(-0.01,1.01)\n",
    "        #ax.set_xscale(\"log\")\n",
    "        #ax.set_yscale(\"log\")\n",
    "        ax.set_xlabel(\"# \" + target + \" events\")\n",
    "        ax.set_ylabel(\"AUC of \"+target)\n",
    "        #ax.set_xticks([0,100,200,300])\n",
    "        ax.set_title(target+\" \"+method)\n",
    "        plt.savefig(\"figures/NK_M0151_N\"+target+\"_AUC_\"+tree+\"_\"+acr+\"_\"+method+\".pdf\",bbox_inches = 'tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation between function and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree   = 'mlgtdb'\n",
    "acr    = 'MPPA'\n",
    "\n",
    "test_result_list = []\n",
    "\n",
    "for target, prediction, color in [('gain', 'LR', '#9FA6F1'), ('gain', 'RF', '#9FA6F1'), ('loss', 'LR', '#E1BB63'), ('loss', 'RF', '#E1BB63')]:\n",
    "\n",
    "    df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.\"+tree+\".\"+acr+\".txt\", names = ['KO', 'target', 'method', 'auc'])\n",
    "    df_auc = df_auc_raw.groupby(['KO', 'target', 'method'], as_index = False).mean()\n",
    "\n",
    "    df_category_auc =  pd.merge(df_category_ko, df_auc, on = 'KO')\n",
    "    \n",
    "    category_order = list(reversed(list(df_category_auc[(df_category_auc['target'] == \"gain\") & (df_category_auc['method'] == prediction)].groupby(\"category\", as_index=False).median().sort_values(\"auc\")[\"category\"])))\n",
    "    #category_order = list(reversed(list(df_category_auc[(df_category_auc['target'] == target) & (df_category_auc['method'] == prediction)].groupby(\"category\", as_index=False).median().sort_values(\"auc\")[\"category\"])))\n",
    "    \n",
    "    \n",
    "    df_category_auc_ext = df_category_auc[(df_category_auc['target'] == target) & (df_category_auc['method'] == prediction)]\n",
    "    fig = plt.figure(figsize=(5,1.8))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    sns.violinplot(data = df_category_auc_ext, x = 'category', y = 'auc', order = category_order, linewidth=0.5, orient = 'v', color = '#FFFFFF')\n",
    "    sns.stripplot (data = df_category_auc_ext, x = 'category', y = 'auc', hue = 'target', order = category_order, linewidth=0, orient = 'v', size = 1, alpha=.5,jitter=0.3, dodge=True, palette=[color])\n",
    "    #ax.tick_params(axis='x', labelrotation= 90)\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_xlabel('KEGG category')\n",
    "    ax.tick_params(axis='x', labelrotation= 90)\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    ax.axhline(0.5, linewidth = 1, alpha = 0.5, color = '#555555')\n",
    "    ax.set_title(target + \"/\" + prediction)\n",
    "    plt.savefig(\"figures/NK_M0151_by_category_\"+target + \"_\" + prediction+\".pdf\",bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # test if average AUC is 0.5\n",
    "    for category in sorted(list(set(df_category_auc_ext[\"category\"]))):\n",
    "        test_result_list.append([tree, acr, target, prediction, category, np.median(df_category_auc_ext[df_category_auc_ext['category']==category]['auc']), ttest_1samp(df_category_auc_ext[df_category_auc_ext['category']==category]['auc'], 0.5).pvalue])\n",
    "        \n",
    "        \n",
    "    F_test_result = f_oneway(\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09101 Carbohydrate metabolism\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09102 Energy metabolism\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09103 Lipid metabolism\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09104 Nucleotide metabolism\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09105 Amino acid metabolism\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09106 Metabolism of other amino acids\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09107 Glycan biosynthesis and metabolism\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09108 Metabolism of cofactors and vitamins\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09109 Metabolism of terpenoids and polyketides\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09110 Biosynthesis of other secondary metabolites\"].auc),\n",
    "        list(df_category_auc_ext[df_category_auc_ext[\"category\"]==\"09111 Xenobiotics biodegradation and metabolism\"].auc),\n",
    "    )\n",
    "    \n",
    "    print(\"F-test result\", target, prediction, F_test_result.statistic, F_test_result.pvalue, sep = \"\\t\")\n",
    "    \n",
    "df_test_result = pd.DataFrame(test_result_list, columns=[\"Tree\", \"ACR\", \"Target\", \"Prediction\", \"Function\", \"Median AUC\", \"p\"])\n",
    "df_test_result[\"q\"] = list(multipletests(list(df_test_result[\"p\"]), method = \"fdr_bh\")[1])\n",
    "df_test_result[\"sig\"] = ['*' if q<0.05 else '' for q in df_test_result.q]\n",
    "df_test_result.to_csv(\"tables/NK_M0151_by_category.txt\", index=False, sep = \"\\t\")\n",
    "df_test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare over- and under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare over- and under-sampling\n",
    "\n",
    "df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.mlgtdb.MPPA.sampling.filtered.txt\", names = ['KO','target', 'method', 'auc'])\n",
    "df_auc = df_auc_raw.groupby(['KO', 'target', 'method'], as_index = False).mean()\n",
    "df_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if average AUC is 0.5\n",
    "for method in ['LR_none','LR_over','LR_under', 'RF_none', 'RF_over', 'RF_none']:\n",
    "    for target in ['gain', 'loss']:\n",
    "            print(tree, acr, target, method, ttest_1samp(df_auc[(df_auc['method'] == method) & (df_auc['target'] == target)]['auc'], 0.5).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 2))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax.set_ylim(-0.1,1.1)\n",
    "sns.violinplot(data = df_auc, x = 'method', y = 'auc', hue = 'target', linewidth=0.5, order = ['RF_none','RF_under','RF_over','LR_none', 'LR_under', 'LR_over'], palette = ['#FFFFFF'], orient = 'v')\n",
    "sns.stripplot (data = df_auc, x = 'method', y = 'auc', hue = 'target', linewidth=0, order = ['RF_none','RF_under','RF_over','LR_none', 'LR_under', 'LR_over'], palette = ['#9FA6F1', '#E1BB63'], size = 1, alpha=.3,jitter=0.3, dodge=True, orient = 'v')\n",
    "ax.get_legend().remove()\n",
    "ax.set_ylabel('AUC')\n",
    "ax.set_ylim(-0.1,1.1)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "ax.axhline(0.5, linewidth = 1, alpha = 0.5, color = '#555555')\n",
    "ax.set_xticklabels(['RF$_{none}$','RF$_{under}$','RF$_{over}$', 'LR$_{none}$', 'LR$_{under}$', 'LR$_{over}$'])\n",
    "plt.savefig(\"figures/NK_M0151_underover.pdf\",bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised clustering of OGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised clustering of OGs\n",
    "df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.mlgtdb.MPPA.clustering.filtered.txt\", names = ['KO','target', 'method', 'auc', 'Ncluster'])\n",
    "df_auc = df_auc_raw.groupby(['KO', 'target', 'method', 'Ncluster'], as_index = False).mean()\n",
    "df_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate AUC for each number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for method, target, color in [('LR','loss','#E1BB63'), ('LR','gain','#9FA6F1'), ('RF','loss','#E1BB63'), ('RF','gain','#9FA6F1')]:\n",
    "\n",
    "    df_auc_ext = df_auc[(df_auc['method']==method) & (df_auc['target']==target)]\n",
    "\n",
    "    # clustering\n",
    "    fig = plt.figure(figsize=(2,7))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    sns.violinplot(data = df_auc_ext, y = 'Ncluster', x = 'auc', linewidth=0.5, order = [1,2,3,4,5,6,7,8,9,10,20,30,40,50], color = '#FFFFFF', orient = 'h')\n",
    "    sns.stripplot (data = df_auc_ext, y = 'Ncluster', x = 'auc', linewidth=0,   order = [1,2,3,4,5,6,7,8,9,10,20,30,40,50], color = color, size = 1, alpha=.3, jitter=0.3, dodge=True, orient = 'h')\n",
    "\n",
    "    df_Ncluster_medAUC = df_auc_ext.groupby(\"Ncluster\", as_index=False).median()\n",
    "    #ax.plot(df_Ncluster_medAUC.auc)\n",
    "\n",
    "    #ax.get_legend().remove()\n",
    "    ax.set_xlabel('AUC')\n",
    "    ax.set_xlim(-0.1,1.1)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    ax.axvline(0.5, linewidth = 1, alpha = 0.5, color = '#555555')\n",
    "\n",
    "    ax.set_title(target+\" \"+method)\n",
    "    \n",
    "    plt.savefig(\"figures/NK_M0151_clustering_\"+target+\"_\"+method+\".pdf\",bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of OGs which is significantly predictable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.10\n",
    "\n",
    "df_pvalue_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_p.mlgtdb.MPPA.clustering.filtered.txt\", names = ['KO','target', 'method', 'p', 'Ncluster'])\n",
    "df_pvalue = df_pvalue_raw.groupby(['KO', 'target', 'method', 'Ncluster'], as_index = False).median()\n",
    "list_target_method_Ncluster_Npredictable = []\n",
    "for target in [\"gain\",\"loss\"]:\n",
    "    for method in [\"LR\", \"RF\"]:\n",
    "        for Ncluster in [1,2,3,4,5,6,7,8,9,10,20,30,40,50]:\n",
    "            df_pvalue_ext = df_pvalue[(df_pvalue[\"target\"]==target) & (df_pvalue[\"method\"]==method) & (df_pvalue[\"Ncluster\"] == Ncluster)]\n",
    "            df_pvalue_ext = df_pvalue_ext.reset_index()\n",
    "            df_pvalue_ext[\"q\"] = list(multipletests(list(df_pvalue_ext.loc[:,\"p\"]), method = \"fdr_bh\")[1])\n",
    "            list_target_method_Ncluster_Npredictable.append([target, method, Ncluster, len(df_pvalue_ext[df_pvalue_ext[\"q\"] < threshold])])\n",
    "\n",
    "        df_pvalue_raw_without_clustering = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_p.mlgtdb.MPPA.txt\", names = ['KO','target', 'method', 'p'])\n",
    "        df_pvalue_without_clustering = df_pvalue_raw_without_clustering.groupby(['KO', 'target', 'method'], as_index = False).median()\n",
    "        df_pvalue_without_clustering_ext = df_pvalue_without_clustering[(df_pvalue_without_clustering[\"target\"]==target) & (df_pvalue_without_clustering[\"method\"]==method)]\n",
    "        df_pvalue_without_clustering_ext = df_pvalue_without_clustering_ext.reset_index()\n",
    "        df_pvalue_without_clustering_ext[\"q\"] = list(multipletests(list(df_pvalue_without_clustering_ext.loc[:,\"p\"]), method = \"fdr_bh\")[1])\n",
    "        list_target_method_Ncluster_Npredictable.append([target, method, 70, sum(df_pvalue_without_clustering_ext[\"q\"] < threshold)])\n",
    "\n",
    "df_target_method_Ncluster_Npredictable = pd.DataFrame(list_target_method_Ncluster_Npredictable, columns = [\"target\", \"method\", \"Ncluster\", \"Npredictable\"])\n",
    "df_target_method_Ncluster_Npredictable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in [\"LR\", \"RF\"]:\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "    df_target_method_Ncluster_Npredictable_ext = \\\n",
    "        df_target_method_Ncluster_Npredictable[\n",
    "            (df_target_method_Ncluster_Npredictable[\"target\"]==\"gain\") & \\\n",
    "            (df_target_method_Ncluster_Npredictable[\"method\"]==method)\n",
    "            ]\n",
    "    ax.scatter(x = df_target_method_Ncluster_Npredictable_ext[\"Ncluster\"], y = df_target_method_Ncluster_Npredictable_ext[\"Npredictable\"], color = '#9FA6F1', s = 20, alpha = 0.8)\n",
    "\n",
    "    df_target_method_Ncluster_Npredictable_ext = \\\n",
    "        df_target_method_Ncluster_Npredictable[\n",
    "            (df_target_method_Ncluster_Npredictable[\"target\"]==\"loss\") & \\\n",
    "            (df_target_method_Ncluster_Npredictable[\"method\"]==method)\n",
    "            ]\n",
    "    ax.scatter(x = df_target_method_Ncluster_Npredictable_ext[\"Ncluster\"], y = df_target_method_Ncluster_Npredictable_ext[\"Npredictable\"], color = '#E1BB63', s = 20, alpha = 0.8)\n",
    "\n",
    "    ax.set_title(method)\n",
    "\n",
    "    #ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"#merged features\")\n",
    "    ax.set_ylabel(\"#predictable OGs\")\n",
    "    ax.set_xlim(0,75)\n",
    "    ax.set_ylim(0, 1800)\n",
    "    ax.set_xticks([0,10,20,30,40,50,70])\n",
    "    ax.set_xticklabels([0,10,20,30,40,50,\"all\"])\n",
    "    plt.savefig(\"figures/NK_M0151_clustering_\"+method+\"_Npredictable.pdf\",bbox_inches='tight')\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in [\"LR\", \"RF\"]:\n",
    "    fig = plt.figure(figsize=(1,1))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "    df_target_method_Ncluster_Npredictable_ext = \\\n",
    "        df_target_method_Ncluster_Npredictable[\n",
    "            (df_target_method_Ncluster_Npredictable[\"target\"]==\"gain\") & \\\n",
    "            (df_target_method_Ncluster_Npredictable[\"method\"]==method)\n",
    "            ]\n",
    "    ax.scatter(x = df_target_method_Ncluster_Npredictable_ext[\"Ncluster\"], y = df_target_method_Ncluster_Npredictable_ext[\"Npredictable\"], color = '#9FA6F1', s = 10, alpha = 0.8)\n",
    "\n",
    "    df_target_method_Ncluster_Npredictable_ext = \\\n",
    "        df_target_method_Ncluster_Npredictable[\n",
    "            (df_target_method_Ncluster_Npredictable[\"target\"]==\"loss\") & \\\n",
    "            (df_target_method_Ncluster_Npredictable[\"method\"]==method)\n",
    "            ]\n",
    "    ax.scatter(x = df_target_method_Ncluster_Npredictable_ext[\"Ncluster\"], y = df_target_method_Ncluster_Npredictable_ext[\"Npredictable\"], color = '#E1BB63', s = 10, alpha = 0.8)\n",
    "\n",
    "    ax.set_title(method)\n",
    "\n",
    "    #ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"#merged features\")\n",
    "    ax.set_ylabel(\"#predictable OGs\")\n",
    "    ax.set_xticks([1,2,3,4,5])\n",
    "    ax.set_xticklabels([1,2,3,4,5])\n",
    "    \n",
    "    ax.set_xlim(0.5, 5.5)\n",
    "    ax.set_ylim(-5,80)\n",
    "    plt.savefig(\"figures/NK_M0151_clustering_\"+method+\"_Npredictable_expanded.pdf\",bbox_inches='tight')\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functional enrichment analysis of predictable OGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/analysis/result/enrichment_gain_LR.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list up predictable OGs\n",
    "threshold = 0.05\n",
    "for target in [\"gain\",\"loss\"]:\n",
    "    for method in [\"LR\", \"RF\"]:\n",
    "        df_pvalue_raw_without_clustering = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_p.mlgtdb.MPPA.txt\", names = ['KO','target', 'method', 'p'])\n",
    "        df_pvalue_without_clustering = df_pvalue_raw_without_clustering.groupby(['KO', 'target', 'method'], as_index = False).median()\n",
    "        df_pvalue_without_clustering_ext = df_pvalue_without_clustering[(df_pvalue_without_clustering[\"target\"]==target) & (df_pvalue_without_clustering[\"method\"]==method)]\n",
    "        df_pvalue_without_clustering_ext = df_pvalue_without_clustering_ext.reset_index()\n",
    "        df_pvalue_without_clustering_ext[\"q\"] = list(multipletests(list(df_pvalue_without_clustering_ext.loc[:,\"p\"]), method = \"fdr_bh\")[1])\n",
    "        df_pvalue_without_clustering_ext_predictable = df_pvalue_without_clustering_ext[df_pvalue_without_clustering_ext[\"q\"] < threshold]\n",
    "        df_pvalue_without_clustering_ext_predictable.to_csv(\"tables/ko_p.predictable.unclustered_\"+target+\"_\"+method+\".txt\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"gain\"\n",
    "color  = \"#9FA6F1\"\n",
    "method = \"LR\"\n",
    "Ncluster = 1\n",
    "df_pvalue_ext = df_pvalue[(df_pvalue[\"target\"]==target) & (df_pvalue[\"method\"]==method) & (df_pvalue[\"Ncluster\"] == Ncluster)]\n",
    "df_pvalue_ext = df_pvalue_ext.reset_index()\n",
    "df_pvalue_ext[\"q\"] = list(multipletests(list(df_pvalue_ext.loc[:,\"p\"]), method = \"fdr_bh\")[1])\n",
    "df_pvalue_gain_predictable_one_cluster = df_pvalue_ext[df_pvalue_ext[\"q\"]<0.10]\n",
    "df_auc_gain_predictable_one_cluster = pd.merge(df_pvalue_gain_predictable_one_cluster['KO'], df_auc[(df_auc['target']==\"gain\") & (df_auc['method']==\"LR\")], on = 'KO', how = 'left')\n",
    "df_auc_gain_predictable_one_cluster_maxauc = df_auc_gain_predictable_one_cluster.loc[df_auc_gain_predictable_one_cluster.groupby(\"KO\")[\"auc\"].idxmax(), :]\n",
    "\n",
    "KO_of_interest = df_auc_gain_predictable_one_cluster_maxauc[df_auc_gain_predictable_one_cluster_maxauc[\"Ncluster\"]==1].KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occurrence = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_target_gn_Ngenes_bin.txt\", names = ['KO', 'target', 'node', 'Ngenes', 'Occurrence'])\n",
    "\n",
    "df_KO_Ngenes = pd.merge(KO_of_interest, df_occurrence[df_occurrence[\"target\"]=='gain'], on = 'KO')\n",
    "df_KO_Ngenes[\"z-Ngenes\"] = df_KO_Ngenes.groupby('KO').transform(zscore)['Ngenes']\n",
    "df_KO_Ngenes_gained = df_KO_Ngenes[df_KO_Ngenes[\"Occurrence\"] == 1]\n",
    "df_ko_desc = pd.read_table(\"/Users/konnonaoki/GoogleDrive/Research/KonnoNaoki/repositories/handyenrich/ref/class_description/ko.kegg.txt\", names = [\"ko\", \"description\"])\n",
    "df_ko_desc[\"KO\"] = [ko.split(\":\")[1] for ko in df_ko_desc['ko']]\n",
    "df_KO_Ngenes_gained = pd.merge(df_KO_Ngenes_gained,df_ko_desc,on = 'KO')\n",
    "df_KO_Ngenes_gained.to_csv(\"tables/KO_Ngenes_gained.txt\", sep = '\\t', index = None)\n",
    "df_node_phylum = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0150/table/node_phylum.mlgtdb_MPPA.txt\", names = [\"node\", \"phylum\"])\n",
    "df_KO_Ngenes_gained = pd.merge(df_KO_Ngenes_gained,df_node_phylum,on = 'node')\n",
    "df_KO_Ngenes_gained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KO_meanNgenes_gained = df_KO_Ngenes_gained.groupby(\"KO\", as_index=False).mean().sort_values(\"Ngenes\")\n",
    "df_KO_meanNgenes_gained = pd.merge(df_KO_meanNgenes_gained,df_ko_desc,on = 'KO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phylum_Nspecies_color_name = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0150/table/phylum_Nspecies_color_name.txt\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ancnode_Ngenes = df_KO_Ngenes[['node','Ngenes']].groupby('node',as_index=False).mean()\n",
    "fig = plt.figure(figsize=(3,1.5))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax.hist(df_ancnode_Ngenes.Ngenes,range=(0,1200), bins = 50, color = '#00FFAA', alpha =0.5)\n",
    "ax.set_ylabel('#ancestral species')\n",
    "ax.set_xlim(0,1200)\n",
    "plt.savefig(\"figures/NK_M0151_histogram_Ngenes_ancestors.pdf\",bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,10))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "sns.stripplot (\n",
    "    data = df_KO_Ngenes_gained, \n",
    "    y = 'KO', \n",
    "    x = 'Ngenes', \n",
    "    hue = 'phylum', \n",
    "    order = list(df_KO_Ngenes.groupby(\"KO\").mean().sort_values(\"Ngenes\").index), \n",
    "    hue_order = list(df_phylum_Nspecies_color_name.Phylum)   + ['upstream'], \n",
    "    palette   = list(df_phylum_Nspecies_color_name['color']) + ['#EEEEEE'] , \n",
    "    linewidth=0, \n",
    "    orient = 'h', \n",
    "    size = 2, \n",
    "    alpha=1,\n",
    "    jitter=0.1\n",
    "    )\n",
    "\n",
    "ax.plot(df_KO_meanNgenes_gained['Ngenes'], df_KO_meanNgenes_gained[\"KO\"], color = color, linewidth = 1, alpha = 0.5)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(-1.55, 1), loc='upper left')\n",
    "\n",
    "ax.set_ylim(32.5, -0.5)\n",
    "ax.set_xlim(0,1200)\n",
    "ax.set_xlabel(\"#possessed OGs\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(32.5, -0.5)\n",
    "ax2.set_yticks(ax.get_yticks())\n",
    "ax2.set_yticklabels(df_KO_meanNgenes_gained.description) \n",
    "\n",
    "plt.savefig(\"figures/NK_M0151_clustering_\"+method+\"_total_Ngenes.pdf\",bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,10))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "sns.stripplot (\n",
    "    data = df_KO_Ngenes_gained, \n",
    "    y = 'KO', \n",
    "    x = 'z-Ngenes', \n",
    "    hue = 'phylum', \n",
    "    order = list(df_KO_Ngenes.groupby(\"KO\").mean().sort_values(\"Ngenes\").index), \n",
    "    hue_order = list(df_phylum_Nspecies_color_name.Phylum)   + ['upstream'], \n",
    "    palette   = list(df_phylum_Nspecies_color_name['color']) + ['#EEEEEE'] , \n",
    "    linewidth=0, \n",
    "    orient = 'h', \n",
    "    size = 2, \n",
    "    alpha=1,\n",
    "    jitter=0.1\n",
    "    )\n",
    "ax.legend(bbox_to_anchor=(-1.55, 1), loc='upper left')\n",
    "ax.axvline(0, linewidth = 1, alpha = 0.5, color = '#555555')\n",
    "ax.set_xlim(-2.5,2.5)\n",
    "ax.set_xlabel(\"Z-score of #possessed OGs\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(32.5, -0.5)\n",
    "ax2.set_yticks(ax.get_yticks())\n",
    "ax2.set_yticklabels(df_KO_meanNgenes_gained.description) \n",
    "\n",
    "plt.savefig(\"figures/NK_M0151_clustering_\"+method+\"_total_Z-Ngenes.pdf\",bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-phylum validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-phylum validation\n",
    "df_auc = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.mlgtdb.MPPA.crossphylum.filtered.txt\", names = ['KO', 'target', 'method', 'auc'])\n",
    "df_auc['Phylum'] = [\"_\".join(method.split(\"_\")[3:]) for method in df_auc.method]\n",
    "df_auc['method'] = [method.split(\"_\")[0] for method in df_auc.method]\n",
    "df_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test_result=[]\n",
    "for method, target, color in [('LR','loss','#E1BB63'), ('LR','gain','#9FA6F1'), ('RF','loss','#E1BB63'), ('RF','gain','#9FA6F1')]:\n",
    "    \n",
    "    df_auc_ext = df_auc[(df_auc['method']==method) & (df_auc['target']==target)].reset_index()\n",
    "    fig = plt.figure(figsize=(5,1.8))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    sns.violinplot(data = df_auc_ext, x = 'Phylum', y = 'auc', linewidth=0.5, order = [\"Proteobacteria\", \"Actinobacteriota\", \"Firmicutes\", \"Bacteroidota\", \"Firmicutes_A\", \"Cyanobacteria\", \"Campylobacterota\", \"Spirochaetota\", \"Firmicutes_I\", \"Deinococcota\"], color = '#FFFFFF', orient = 'v')\n",
    "    sns.stripplot (data = df_auc_ext, x = 'Phylum', y = 'auc', linewidth=0,   order = [\"Proteobacteria\", \"Actinobacteriota\", \"Firmicutes\", \"Bacteroidota\", \"Firmicutes_A\", \"Cyanobacteria\", \"Campylobacterota\", \"Spirochaetota\", \"Firmicutes_I\", \"Deinococcota\"], color = color, size = 1, alpha=.3, jitter=0.3, dodge=True, orient = 'v')\n",
    "\n",
    "    #df_Ncluster_medAUC = df_auc_ext.groupby(\"\", as_index=False).median()\n",
    "    #ax.plot(df_Ncluster_medAUC.auc)\n",
    "\n",
    "    #ax.get_legend().remove()\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    ax.axhline(0.5, linewidth = 1, alpha = 0.5, color = '#555555')\n",
    "    ax.set_title(target + '/' + method)\n",
    "    ax.tick_params(axis='x', labelrotation= 90)\n",
    "    plt.savefig(\"figures/NK_M0151_crossphylum_\"+target+\"_\"+method+\".pdf\",bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    for phylum in [\"Proteobacteria\", \"Actinobacteriota\", \"Firmicutes\", \"Bacteroidota\", \"Firmicutes_A\", \"Cyanobacteria\", \"Campylobacterota\", \"Spirochaetota\", \"Firmicutes_I\", \"Deinococcota\"]:\n",
    "        list_test_result.append([phylum, target, method, ttest_1samp(df_auc_ext[(df_auc_ext['method'] == method) & (df_auc_ext['target'] == target) &  (df_auc_ext['Phylum'] == phylum)]['auc'], 0.5).pvalue])\n",
    "        \n",
    "    F_test_result = f_oneway(\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Proteobacteria\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Actinobacteriota\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Firmicutes\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Bacteroidota\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Firmicutes_A\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Cyanobacteria\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Campylobacterota\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Spirochaetota\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Firmicutes_I\"].auc),\n",
    "        list(df_auc_ext[df_auc_ext[\"Phylum\"]==\"Deinococcota\"].auc),\n",
    "    )\n",
    "    \n",
    "    print(\"F-test result\", target, method, F_test_result.statistic, F_test_result.pvalue, sep = \"\\t\")\n",
    "\n",
    "df_test_result = pd.DataFrame(list_test_result, columns = ['Phylum', 'target', 'prediction_method', 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_result['q'] =  list(multipletests(list(df_test_result.p), method = \"fdr_bh\")[1])\n",
    "df_test_result['significant'] = ['*' if q<0.05 else '' for q in df_test_result.q]\n",
    "df_test_result.to_csv(\"tables/NK_M0151_crossphylum.txt\", index=False, sep = \"\\t\")\n",
    "df_test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction from interpretable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = 'mlgtdb'\n",
    "acr  = 'MPPA'\n",
    "# Interpretable features\n",
    "df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.mlgtdb.MPPA.interpretable.filtered.txt\", names = ['KO', 'target', 'method', 'auc', 'features'])\n",
    "df_auc        = df_auc_raw.groupby(['KO', 'target', 'method', 'features'], as_index = False).mean()\n",
    "df_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method, target, color in [('LR','loss','#E1BB63'), ('LR','gain','#9FA6F1'), ('RF','loss','#E1BB63'), ('RF','gain','#9FA6F1')]:\n",
    "\n",
    "    df_auc_ext = df_auc[(df_auc['method']==method) & (df_auc['target']==target)]\n",
    "\n",
    "    # clustering\n",
    "    fig = plt.figure(figsize=(3.5,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    sns.violinplot(data = df_auc_ext, x = 'features', y = 'auc', linewidth=0.5, order = [\"md\", \"ec12\", \"path\", \"ec12md\", \"ec12path\", \"mdpath\", \"ec12mdpath\"], color = '#FFFFFF')\n",
    "    sns.stripplot (data = df_auc_ext, x = 'features', y = 'auc', linewidth=0,   order = [\"md\", \"ec12\", \"path\", \"ec12md\", \"ec12path\", \"mdpath\", \"ec12mdpath\"], color = color, size = 1, alpha=.3, jitter=0.3, dodge=True)\n",
    "\n",
    "    df_auc_ext_meanAUC = df_auc_ext.groupby(\"features\", as_index=False).mean()\n",
    "    print(df_auc_ext_meanAUC.sort_values('auc'))\n",
    "    #ax.scatter(y = df_auc_ext_meanAUC.features, x = df_auc_ext_meanAUC.auc, s = 5, marker = \"|\",zorder=5)\n",
    "\n",
    "    #ax.get_legend().remove()\n",
    "    ax.set_xlabel('Feature set')\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    ax.axhline(0.5, linewidth = 1, alpha = 0.5, color = '#555555')\n",
    "    ax.set_xticklabels([\"M\", \"E\", \"P\", \"ME\", \"EP\", \"PM\", \"MEP\"])\n",
    "\n",
    "    ax.set_title(target+\" \"+method)\n",
    "    \n",
    "    plt.savefig(\"figures/NK_M0151_interpretable_\"+target+\"_\"+method+\".pdf\",bbox_inches='tight')\n",
    "    #plt.close()\n",
    "\n",
    "    # test if AUC of X and Y is equal\n",
    "    for comp_x, comp_y in [(\"md\", \"ec12\"), (\"md\", \"path\"), (\"ec12\", \"path\")]:\n",
    "        df_auc_comp = pd.merge(df_auc_ext[(df_auc_ext['features'] == comp_x) & (df_auc_ext['target'] == target)], df_auc_ext[(df_auc_ext['features'] == comp_y) & (df_auc_ext['target'] == target)], on = 'KO')\n",
    "        #print(tree, acr, target, method, comp_x, comp_y, wilcoxon(df_auc_comp['auc_x'], df_auc_comp['auc_y']))\n",
    "        print(tree, acr, target, method, comp_x, comp_y, ttest_rel(df_auc_comp['auc_x'], df_auc_comp['auc_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretable features \n",
    "\n",
    "df_auc_raw = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/ko_auc.mlgtdb.MPPA.Nselected.filtered.txt\", names = ['KO', 'target', 'pred_method', 'featureset', 'selec_method', 'Nfeatures', 'AUC']) \n",
    "df_auc = df_auc_raw.groupby(['KO', 'target', 'pred_method', 'featureset', 'selec_method', 'Nfeatures'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Nfeatures_medAUC(df_auc, target, pred_method, featureset, selec_method, ax, color, label = None):\n",
    "    df_auc_ext = df_auc[(df_auc['target']==target) & (df_auc['pred_method']==pred_method) & (df_auc['featureset']==featureset) & (df_auc['selec_method']==selec_method)]\n",
    "    #plt.scatter(df_auc_ext[df_auc_ext['KO']=='K00002']['Nfeatures'], df_auc_ext[df_auc_ext['KO']=='K00002']['AUC'])\n",
    "\n",
    "    df_auc_ext_5 = df_auc_ext.groupby(['Nfeatures'], as_index = False).quantile(0.05)\n",
    "    df_auc_ext_50 = df_auc_ext.groupby(['Nfeatures'], as_index = False).quantile(0.5)\n",
    "    df_auc_ext_95 = df_auc_ext.groupby(['Nfeatures'], as_index = False).quantile(0.95)\n",
    "    df_auc_ext_percentile = \\\n",
    "        pd.merge(\n",
    "            pd.merge(\n",
    "                df_auc_ext_5, df_auc_ext_50, on = 'Nfeatures'\n",
    "                ), \n",
    "                df_auc_ext_95\n",
    "            )\n",
    "    df_auc_ext_percentile = df_auc_ext_percentile.rename(columns = {'AUC_x':'AUC_5', 'AUC_y': 'AUC_50', 'AUC': 'AUC_95'})\n",
    "    #print(target, pred_method, selec_method, featureset, df_auc_ext_percentile.sort_values('AUC_50', ascending=False))\n",
    "    ax.plot(df_auc_ext_percentile['Nfeatures'], df_auc_ext_percentile['AUC_50'], color= color, label = label)\n",
    "\n",
    "colors = ['#66C2A5', '#FC8D62', '#8DA0CB', '#E78AC3']\n",
    "for featureset in ['md', 'ec12md', 'ec12mdpath']:\n",
    "    for target in ['gain', 'loss']:\n",
    "        fig = plt.figure(figsize=(2,2))\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax.set_xlim(0,51)\n",
    "        ax.set_ylim(0.5, 0.8)\n",
    "        ax.set_xlabel(\"#selected featues\")\n",
    "        ax.set_ylabel(\"Median AUC\")\n",
    "        ax.set_title(featureset + \" \" + target)\n",
    "\n",
    "        i = 0\n",
    "        for pred_method in ['LR', 'RF']:\n",
    "            for selec_method in ['ANOVA', 'RandomForest']:\n",
    "                plot_Nfeatures_medAUC(df_auc, target, pred_method, featureset, selec_method, ax, colors[i])\n",
    "                i+=1\n",
    "        plt.savefig(\"figures/NK_M0151_Nfeatures_medAUC_\"+featureset+\"_\"+target+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for featureset in ['md']:\n",
    "    for target in ['gain', 'loss']:\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax.set_xlim(0,51)\n",
    "        ax.set_ylim(0.55, 0.85)\n",
    "        ax.set_xlabel(\"#selected featues\")\n",
    "        ax.set_ylabel(\"Median AUC\")\n",
    "        ax.set_title(featureset + \" \" + target)\n",
    "        \n",
    "        df_auc_category = pd.merge(df_auc, df_category_ko, on = 'KO')\n",
    "\n",
    "        i = 0\n",
    "        for category in sorted(list(set(df_auc_category.category))):\n",
    "            for pred_method in ['RF']:\n",
    "                for selec_method in ['ANOVA']:\n",
    "                    plot_Nfeatures_medAUC(df_auc_category[df_auc_category.category == category], target, pred_method, featureset, selec_method, ax, mcolor.rgb2hex(cm(i)), label = category)\n",
    "                    i+=1\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left',borderaxespad=0,)\n",
    "        \n",
    "        plt.savefig(\"figures/NK_M0151_Nfeatures_medAUC_\"+featureset+\"_\"+target+\"_category_RF_ANOVA.pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsemtx2mtx(X, Y, Z):\n",
    "    X_uniq_list = list(sorted(list(set(X))))\n",
    "    Y_uniq_list = list(sorted(list(set(Y))))\n",
    "    Z_matrix    = np.zeros((len(X_uniq_list), len(Y_uniq_list)))\n",
    "    for x, y, z in zip(X, Y, Z):\n",
    "        x_idx = X_uniq_list.index(x)\n",
    "        y_idx = Y_uniq_list.index(y)\n",
    "        Z_matrix[x_idx, y_idx] = z\n",
    "    #return X_uniq_list, Y_uniq_list, Z_matrix\n",
    "    return pd.DataFrame(Z_matrix, index = X_uniq_list, columns = Y_uniq_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['gain', 'loss']:\n",
    "\n",
    "    selec_method = 'ANOVA'\n",
    "    pred_method = 'RF'\n",
    "    featureset = 'md'\n",
    "    df_auc_ext = df_auc[(df_auc['target']==target) & (df_auc['pred_method']==pred_method) & (df_auc['featureset']==featureset) & (df_auc['selec_method']==selec_method)]\n",
    "\n",
    "    df_KO_Nfeatures_AUC = sparsemtx2mtx(df_auc_ext.KO, df_auc_ext.Nfeatures, df_auc_ext.AUC)\n",
    "\n",
    "    g = sns.clustermap(df_KO_Nfeatures_AUC, col_cluster=False, method = 'ward', metric = 'euclidean', cmap = 'coolwarm', figsize = (5,5), vmin = 0.1, vmax = 0.9)\n",
    "\n",
    "    g.fig.axes[2].set_yticks([])\n",
    "    g.fig.axes[2].set_xticks(np.array([1, 10, 20, 30, 40, 50])-0.5)\n",
    "    g.fig.axes[2].set_xticklabels(np.array([1, 10, 20, 30, 40, 50]))\n",
    "    g.fig.axes[2].set_ylabel(str(len(df_KO_Nfeatures_AUC.index)) + \" OGs\")\n",
    "    g.fig.axes[2].set_xlabel(\"# selected features\")\n",
    "    g.fig.axes[2].set_title(featureset + \" \" + target + \" \" + selec_method + \" \" + pred_method)\n",
    "    g.fig.axes[3].set_title(\"AUC\")\n",
    "\n",
    "    plt.savefig(\"figures/NK_M0151_KO_Nfeatures_AUC_\"+featureset+\"_\"+target+\".pdf\", bbox_inches = 'tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'gain'\n",
    "selec_method = 'RandomForest'\n",
    "pred_method = 'RF'\n",
    "featureset = 'md'\n",
    "df_auc_ext = df_auc[(df_auc['target']==target) & (df_auc['pred_method']==pred_method) & (df_auc['featureset']==featureset) & (df_auc['selec_method']==selec_method)]\n",
    "df_auc_ext_max_AUC = df_auc_ext.loc[df_auc_ext.groupby(\"KO\")[\"AUC\"].idxmax(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by category \n",
    "cm_name = 'Set3' # B->G->R\n",
    "cm = plt.get_cmap(cm_name)\n",
    "\n",
    "df_auc_category = pd.merge(df_auc, df_category_ko, on = 'KO')\n",
    "\n",
    "for target in ['gain', 'loss']:\n",
    "    fig = plt.figure(figsize=(2,1))\n",
    "    \n",
    "    i = 0\n",
    "    for category in sorted(list(set(df_auc_category.category))):\n",
    "        for pred_method in ['RF']:\n",
    "            for selec_method in ['ANOVA']:\n",
    "                ax = fig.add_axes([0.1,0.1-i,0.8,0.8], label = category)\n",
    "                ax.set_xlim(0,51)\n",
    "                if (i == len(set(df_auc_category.category)) - 1): ax.set_xlabel(\"Optimal # features\")\n",
    "                if (i != len(set(df_auc_category.category)) - 1): ax.set_xticklabels([])\n",
    "                ax.set_ylabel(\"# OGs\")\n",
    "                #ax.set_title(category)\n",
    "                plt.gca().spines['right'].set_visible(False)\n",
    "                plt.gca().spines['top'].set_visible(False)\n",
    "                df_auc_category_ext = df_auc_category[(df_auc_category['target']==target) & (df_auc_category['pred_method']==pred_method) & (df_auc_category['featureset']==featureset) & (df_auc_category['selec_method']==selec_method) & (df_auc_category['category']==category)]\n",
    "                df_auc_ext_max_AUC = df_auc_category_ext.loc[df_auc_category_ext.groupby(\"KO\")[\"AUC\"].idxmax(), :]\n",
    "                ax.hist(df_auc_ext_max_AUC.Nfeatures, range= (0,50), bins = 25, histtype= 'stepfilled', color = mcolor.rgb2hex(cm(i)), alpha = 0.8)\n",
    "                i+=1\n",
    "    plt.savefig(\"figures/NK_M0151_Nfeatures_of_maxAUC_\"+featureset+\"_\"+target+\"_category.pdf\", bbox_inches = 'tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2,2))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax.set_xlim(0,51)\n",
    "ax.set_xlabel(\"Optimal # features\")\n",
    "ax.set_ylabel(\"# OGs\")\n",
    "ax.set_title(featureset, )\n",
    "\n",
    "for target, color in [('gain', '#9FA6F1'), ('loss', '#E1BB63')]:\n",
    "    for pred_method in ['RF']:\n",
    "        for selec_method in ['ANOVA']:\n",
    "            df_auc_ext = df_auc[(df_auc['target']==target) & (df_auc['pred_method']==pred_method) & (df_auc['featureset']==featureset) & (df_auc['selec_method']==selec_method)]\n",
    "            df_auc_ext_max_AUC = df_auc_ext.loc[df_auc_ext.groupby(\"KO\")[\"AUC\"].idxmax(), :]\n",
    "            ax.hist(df_auc_ext_max_AUC.Nfeatures, range= (0,50), bins = 50, histtype= 'step', color = color, alpha = 0.8)\n",
    "plt.savefig(\"figures/NK_M0151_Nfeatures_of_maxAUC_\"+featureset+\"_category_RF_ANOVA.pdf\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'gain'\n",
    "selec_method = 'ANOVA'\n",
    "pred_method = 'RF'\n",
    "featureset = 'md'\n",
    "\n",
    "df_auc_ext = df_auc[(df_auc['target']==target) & (df_auc['pred_method']==pred_method) & (df_auc['featureset']==featureset) & (df_auc['selec_method']==selec_method)]\n",
    "df_auc_ext_max_AUC = df_auc_ext.loc[df_auc_ext.groupby(\"KO\")[\"AUC\"].idxmax(), :]\n",
    "\n",
    "df_auc_ext_max_AUC_Nreaction = pd.merge(df_auc_ext_max_AUC, df_rn_ko.KO.value_counts().reset_index().rename(columns={'index':'KO', 'KO': 'Nreactions'}), on = 'KO')\n",
    "df_auc_ext_max_AUC_Nmodule = pd.merge(df_auc_ext_max_AUC, df_md_ko.KO.value_counts().reset_index().rename(columns={'index':'KO', 'KO': 'Nmodules'}), on = 'KO')\n",
    "\n",
    "fig = plt.figure(figsize=(3,2))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "df_auc_ext_max_AUC_Nreaction['promiscuity'] = ['1' if Nreaction == 1 else '2-10' if Nreaction <= 10 else '11-20' if Nreaction <= 20 else '>20' for Nreaction in df_auc_ext_max_AUC_Nreaction.Nreactions]\n",
    "sns.boxplot(data = df_auc_ext_max_AUC_Nreaction, y = 'Nfeatures', x = 'promiscuity', linewidth=0.5, color = '#FFFFFF', order = ['1', '2-10', '11-20', '>20'])\n",
    "sns.stripplot(data = df_auc_ext_max_AUC_Nreaction, y = 'Nfeatures', x = 'promiscuity', linewidth=0.5, color = '#FF0000', alpha = 0.1, s = 1, order = ['1', '2-10', '11-20', '>20'], jitter = 0.3)\n",
    "ax.set_xlabel(\"Promiscuity (#reactions involved)\")\n",
    "ax.set_ylabel(\"Optimal #features\")\n",
    "ax.set_title(featureset + \" \" + target + \" \" + selec_method + \" \" + pred_method)\n",
    "plt.savefig(\"figures/NK_M0151_optNfeatures_Nreactions_\"+target+\"_\"+featureset+\".pdf\", bbox_inches = 'tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,2))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "sns.boxplot(data = df_auc_ext_max_AUC_Nmodule, y = 'Nfeatures', x = 'Nmodules', linewidth=0.5, color = '#FFFFFF', )\n",
    "sns.stripplot (data = df_auc_ext_max_AUC_Nmodule, y = 'Nfeatures', x = 'Nmodules', linewidth=0, color = '#000000', size = 1, alpha=.3, jitter=.3, dodge=True)\n",
    "ax.set_xlabel(\"#modules involved\")\n",
    "ax.set_ylabel(\"Optimal #features\")\n",
    "ax.set_title(featureset + \" \" + target + \" \" + selec_method + \" \" + pred_method)\n",
    "plt.savefig(\"figures/NK_M0151_optNfeatures_Nmodules_\"+target+\"_\"+featureset+\".pdf\", bbox_inches = 'tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc_ext_max_AUC_category = pd.merge(df_auc_ext_max_AUC, df_category_ko, on = 'KO')\n",
    "sns.violinplot(data = df_auc_ext_max_AUC_category, y = 'category', x = 'Nfeatures', hue = 'target', order = sorted(list(set(df_auc_ext_max_AUC_category['category']))), linewidth=0.5, orient = 'h', color = '#FFFFFF', alpha = 0)\n",
    "sns.stripplot (data = df_auc_ext_max_AUC_category, y = 'category', x = 'Nfeatures', hue = 'target', order = sorted(list(set(df_auc_ext_max_AUC_category['category']))), linewidth=0, orient = 'h', size = 1, alpha=.5,jitter=0.3, dodge=True, palette=['#FF0000'])\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc_ext_max_AUC_Ncategory = pd.merge(df_auc_ext_max_AUC, df_category_ko.KO.value_counts().reset_index().rename(columns={'index':'KO', 'KO': 'Ncategories'}), on = 'KO')\n",
    "fig = plt.figure(figsize=(3,2))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "sns.boxplot(data = df_auc_ext_max_AUC_Ncategory, y = 'Nfeatures', x = 'Ncategories', linewidth=0.5, color = '#FFFFFF', )\n",
    "sns.stripplot(data = df_auc_ext_max_AUC_Ncategory, y = 'Nfeatures', x = 'Ncategories', linewidth=0,   color = '#000000', size = 1, alpha=.3, jitter=0.3, dodge=True)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of selected features: Module vs Module \n",
    "\n",
    "rank_threshold = 14\n",
    "\n",
    "for target in ['gain', 'loss']:\n",
    "\n",
    "    featureset = 'md'\n",
    "    selection  = 'ANOVA'\n",
    "\n",
    "    df_feature_target_method_ko_selectionscore = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/feature_target_method_ko_selectionscore.txt\", names = ['featureset', 'target', 'selection', 'KO', 'feature', 'score'])\n",
    "    df_feature_target_method_ko_selectionscore['abs_score'] = abs(df_feature_target_method_ko_selectionscore['score'])\n",
    "    df_feature_target_method_ko_selectionscore_ext = \\\n",
    "        df_feature_target_method_ko_selectionscore[\n",
    "            (df_feature_target_method_ko_selectionscore['featureset']==featureset) &\n",
    "            (df_feature_target_method_ko_selectionscore['target']    ==target)     &\n",
    "            (df_feature_target_method_ko_selectionscore['selection'] ==selection)\n",
    "            ]\n",
    "    df_feature_target_method_ko_selectionscore_ext = df_feature_target_method_ko_selectionscore_ext.reset_index()\n",
    "    df_feature_target_method_ko_selectionscore_ext['score_rank_descending'] = df_feature_target_method_ko_selectionscore_ext.groupby([\"target\", \"selection\", \"KO\"])['abs_score'].rank(ascending=False)\n",
    "\n",
    "    df_feature_target_method_ko_selectionscore_ext['selected_top'+str(rank_threshold)] = \\\n",
    "        df_feature_target_method_ko_selectionscore_ext['score_rank_descending'] < rank_threshold\n",
    "    df_feature_target_method_ko_selectionscore_ext['score_rank_top'+str(rank_threshold)] = \\\n",
    "        [max(rank_threshold - rank, 0) for rank in df_feature_target_method_ko_selectionscore_ext['score_rank_descending']]\n",
    "    df_feature_target_method_ko_selectionscore_ext\n",
    "\n",
    "\n",
    "    df_md_ko = pd.read_table(\"tables/md_ko.txt\", names = ['Module','KO'])\n",
    "    df_feature_target_method_ko_selectionscore_MD = pd.merge(df_feature_target_method_ko_selectionscore_ext, df_md_ko, on = 'KO').rename(columns = {'Module':'Module_of_KO'})\n",
    "    df_feature_target_method_ko_selectionscore_MD\n",
    "\n",
    "    df_feature_target_method_md_selectionscore_MD = df_feature_target_method_ko_selectionscore_MD.groupby(['target', 'selection', 'Module_of_KO', 'feature'], as_index= False).mean()\n",
    "    df_feature_target_method_md_selectionscore_MD\n",
    "\n",
    "    df_md_md_rank = sparsemtx2mtx(\n",
    "        df_feature_target_method_md_selectionscore_MD.Module_of_KO, \n",
    "        df_feature_target_method_md_selectionscore_MD.feature,\n",
    "        df_feature_target_method_md_selectionscore_MD['selected_top'+str(rank_threshold)]\n",
    "        )\n",
    "\n",
    "    df_category_ko_module = pd.merge(df_category_ko, df_md_ko, on = 'KO')\n",
    "    df_category_ko_module['Nko'] = 1\n",
    "    df_category_module_count = df_category_ko_module.groupby(['category', 'Module'], as_index = False).sum()\n",
    "    df_maxcategory_module = df_category_module_count.loc[df_category_module_count.groupby('Module')['Nko'].idxmax(),:].sort_values('category')\n",
    "    df_maxcategory_module = df_maxcategory_module.reset_index().loc[:, ['category', 'Module']]\n",
    "\n",
    "    df_category_color = pd.DataFrame([[category, i] for i, category in enumerate(df_maxcategory_module.category.unique())], columns = [\"category\", 'category_id'])\n",
    "    df_maxcategory_module_color = pd.merge(df_maxcategory_module, df_category_color)\n",
    "\n",
    "    rows = pd.merge(pd.DataFrame(list(set(df_md_md_rank.index)), columns = ['Module']), df_maxcategory_module_color).sort_values('Module').sort_values('category', kind='mergesort')\n",
    "    columns = pd.merge(pd.DataFrame(list(set(df_md_md_rank.columns)), columns = ['Module']), df_maxcategory_module_color).sort_values('Module').sort_values('category', kind='mergesort')\n",
    "    rows.sort_values('category_id')\n",
    "\n",
    "\n",
    "    # plot a figure\n",
    "    df_md_md_rank = df_md_md_rank.loc[rows.Module, columns.Module]\n",
    "\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    ax2 = fig.add_axes([0.93,0.1,0.05,0.3])\n",
    "    sns.heatmap(df_md_md_rank, ax = ax, cbar_ax = ax2, cmap = 'inferno')\n",
    "    ax.tick_params(bottom = False, left = False, labelbottom = False, labelleft = False)\n",
    "    ax2.set_yticklabels([0, 0.25, 0.5, 1])\n",
    "\n",
    "    # user-defined colormap\n",
    "    cmap = ListedColormap([cm(i) for i in range(11)], name=\"custom\")\n",
    "\n",
    "    # y-axis\n",
    "    ax3 = fig.add_axes([0.05,0.1,0.045,0.8])\n",
    "    sns.heatmap([[color_id] for color_id in rows.category_id], ax = ax3, cbar = False, cmap = cmap)\n",
    "    ax3.tick_params(bottom = False, left = False, labelbottom = False, labelleft = False)\n",
    "    ax3.set_ylabel(\"Modules including predicted OGs\")\n",
    "\n",
    "    # x-axis\n",
    "\n",
    "    ax4 = fig.add_axes([0.1,0.05,0.8,0.045])\n",
    "    sns.heatmap([columns.category_id], ax = ax4, cbar = False, cmap = cmap)\n",
    "    ax4.tick_params(bottom = False, left = False, labelbottom = False, labelleft = False)\n",
    "    ax4.set_xlabel(\"Modules as predictors\")\n",
    "\n",
    "    plt.savefig(\"figures/NK_M0151_selected_features_heatmap_\"+featureset+\"_\"+target+\"_\"+selection+\".pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of important features by functional categories\n",
    "\n",
    "for target, rank_threshold, feature_set, selection in [('gain', 14, 'md', 'ANOVA'), ('gain', 50, 'md', 'RandomForest'), ('loss', 8, 'md', 'ANOVA'), ('loss', 14, 'md', 'RandomForest')]:\n",
    "    \n",
    "    df_feature_target_method_ko_selectionscore = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/feature_target_method_ko_selectionscore.txt\", names = ['featureset', 'target', 'selection', 'KO', 'feature', 'score'])\n",
    "    df_feature_target_method_ko_selectionscore['abs_score'] = abs(df_feature_target_method_ko_selectionscore['score'])\n",
    "    df_feature_target_method_ko_selectionscore_ext = \\\n",
    "        df_feature_target_method_ko_selectionscore[\n",
    "            (df_feature_target_method_ko_selectionscore['featureset']==featureset) &\n",
    "            (df_feature_target_method_ko_selectionscore['target']    ==target)     &\n",
    "            (df_feature_target_method_ko_selectionscore['selection'] ==selection)\n",
    "            ]\n",
    "    df_feature_target_method_ko_selectionscore_ext = df_feature_target_method_ko_selectionscore_ext.reset_index()\n",
    "    df_feature_target_method_ko_selectionscore_ext['score_rank_descending'] = df_feature_target_method_ko_selectionscore_ext.groupby([\"target\", \"selection\", \"KO\"])['abs_score'].rank(ascending=False)\n",
    "    df_ko_feature_scorerank = df_feature_target_method_ko_selectionscore_ext.loc[:, ['KO', 'feature', 'score_rank_descending']]\n",
    "\n",
    "    # select top-N features\n",
    "    df_feature_target_method_ko_selectionscore_ext['selected_top'+str(rank_threshold)] = \\\n",
    "        df_feature_target_method_ko_selectionscore_ext['score_rank_descending'] < rank_threshold\n",
    "    df_feature_target_method_ko_selectionscore_ext['score_rank_top'+str(rank_threshold)] = \\\n",
    "        [max(rank_threshold - rank, 0) for rank in df_feature_target_method_ko_selectionscore_ext['score_rank_descending']]\n",
    "    df_feature_target_method_ko_selectionscore_ext['signed_score_rank_top'+str(rank_threshold)] = df_feature_target_method_ko_selectionscore_ext['score_rank_top'+str(rank_threshold)] * df_feature_target_method_ko_selectionscore_ext['score'] / df_feature_target_method_ko_selectionscore_ext['abs_score']\n",
    "\n",
    "    # \n",
    "    df_feature_target_method_ko_selectionscore_ext = pd.merge(df_feature_target_method_ko_selectionscore_ext, df_uniquecategory_ko, on = 'KO')\n",
    "    df_feature_target_method_ko_selectionscore_ext = df_feature_target_method_ko_selectionscore_ext.fillna(0)\n",
    "    df_feature_target_method_ko_selectionscore_ext_category_sum = df_feature_target_method_ko_selectionscore_ext.groupby(['category', 'feature'], as_index=False).sum()\n",
    "\n",
    "    # Plot 1: Important features for predicting gain/loss of eech KEGG category\n",
    "    fig = plt.figure(figsize=(5,0.5))\n",
    "    list_test_result = []\n",
    "    for i, category in enumerate(df_category_color.category):\n",
    "        df = df_feature_target_method_ko_selectionscore_ext_category_sum[df_feature_target_method_ko_selectionscore_ext_category_sum['category'] == category]\n",
    "        df = pd.merge(df, df_maxcategory_module, left_on = 'feature', right_on = 'Module').sort_values('category_y')\n",
    "        df = pd.merge(df, df_category_color, left_on = 'category_y', right_on = 'category')\n",
    "        \n",
    "        # testing enrichment to the same category\n",
    "        same_category = list(df[df.category_x == df.category_y][\"selected_top\"+str(rank_threshold)])\n",
    "        different_category = list(df[df.category_x != df.category_y][\"selected_top\"+str(rank_threshold)])\n",
    "        list_test_result.append([category, target, rank_threshold, feature_set, selection,mannwhitneyu(same_category, different_category, use_continuity=True, alternative=None).pvalue])\n",
    "        \n",
    "        ax = fig.add_axes([0.1,0.1-i,0.8,0.8])\n",
    "        ax.set_xlim(0,340)\n",
    "        ax.bar(x = df.feature, height = df[\"selected_top\"+str(rank_threshold)], color = df.color)\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "        ax.tick_params(labelbottom=False, bottom=False)\n",
    "        #ax.set_title(category, x = -0.6, y = 0)\n",
    "        ax.text(-0.1,0.45,category,c=df_category_color.color[i],ha='right',transform=ax.transAxes)\n",
    "        #ax.set_ylim(0,130)\n",
    "        if (i==10): ax.set_xlabel(\"Features (339 KEGG Modules)\")\n",
    "        if (i==0):  ax.set_title(\"#OGs\", x=-0.05, fontsize= 10)\n",
    "        if (i==0):  ax.text(0.3,1.5,featureset+\" \"+target+\" \"+selection+\" top \"+str(rank_threshold),ha='left',transform=ax.transAxes)\n",
    "    plt.savefig(\"figures/NK_M0151_nKOs_features_\"+featureset+\"_\"+target+\"_\"+selection+\"_top\"+str(rank_threshold)+\".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    df_test_result = pd.DataFrame(list_test_result, columns = [\"category\", \"target\", \"rank_threshold\", \"feature_set\", \"selection_method\", \"p\"])\n",
    "    df_test_result ['q'] =  list(multipletests(list(df_test_result.p), method = \"fdr_bh\")[1])\n",
    "    df_test_result['significant'] = ['*' if q<0.05 else '' for q in df_test_result.q]\n",
    "    print(df_test_result[df_test_result['q']<0.05])\n",
    "    \n",
    "    # Plot 2: IRank distribution of feature importance\n",
    "    df_ko_md_feature_scorerank = pd.merge(df_md_ko, df_ko_feature_scorerank, on = 'KO').loc[:, ['Module', 'KO', 'feature', 'score_rank_descending']]\n",
    "    df_ko_md_feature_scorerank_same_md = df_ko_md_feature_scorerank[df_ko_md_feature_scorerank['Module']==df_ko_md_feature_scorerank['feature']]\n",
    "\n",
    "    fig = plt.figure(figsize=(3,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    # the module which the predicted OG belongs to\n",
    "    ax.hist(df_ko_md_feature_scorerank_same_md.groupby('KO').mean(), range=(0,339), bins =20, histtype='step',density=True, color ='#008F00', lw=2)\n",
    "    # null distribution\n",
    "    ax.hist(df_ko_feature_scorerank['score_rank_descending'], range=(0,339), bins =20, histtype='stepfilled',density=True, color = '#DDDDDD')\n",
    "    ax.set_xlabel(\"Rank of feature importance\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(featureset+\"_\"+target+\"_\"+selection+\"_top\"+str(rank_threshold))\n",
    "    plt.savefig(\"figures/NK_M0151_feature_importance_\"+featureset+\"_\"+target+\"_\"+selection+\"_top\"+str(rank_threshold)+\".pdf\", bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_feature_target_method_ko_selectionscore_ext(target, rank_threshold, featureset, selection):\n",
    "    \n",
    "    df_feature_target_method_ko_selectionscore = pd.read_table(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/MetabolicNetworkEvolution/experiment/NK_M0151/result/feature_target_method_ko_selectionscore.txt\", names = ['featureset', 'target', 'selection', 'KO', 'feature', 'score'])\n",
    "\n",
    "    df_feature_target_method_ko_selectionscore['abs_score'] = abs(df_feature_target_method_ko_selectionscore['score'])\n",
    "\n",
    "    df_feature_target_method_ko_selectionscore_ext = \\\n",
    "            df_feature_target_method_ko_selectionscore[\n",
    "                (df_feature_target_method_ko_selectionscore['featureset']==featureset) &\n",
    "                (df_feature_target_method_ko_selectionscore['target']    ==target)     &\n",
    "                (df_feature_target_method_ko_selectionscore['selection'] ==selection)\n",
    "                ]\n",
    "\n",
    "    df_feature_target_method_ko_selectionscore_ext = df_feature_target_method_ko_selectionscore_ext.reset_index()\n",
    "    df_feature_target_method_ko_selectionscore_ext['score_rank_descending'] = df_feature_target_method_ko_selectionscore_ext.groupby([\"target\", \"selection\", \"KO\"])['abs_score'].rank(ascending=False)\n",
    "    df_ko_feature_scorerank = df_feature_target_method_ko_selectionscore_ext.loc[:, ['KO', 'feature', 'score_rank_descending']]\n",
    "\n",
    "    # select top-N features\n",
    "    df_feature_target_method_ko_selectionscore_ext['selected_top'+str(rank_threshold)] = \\\n",
    "        df_feature_target_method_ko_selectionscore_ext['score_rank_descending'] < rank_threshold\n",
    "    df_feature_target_method_ko_selectionscore_ext['score_rank_top'+str(rank_threshold)] = \\\n",
    "        [max(rank_threshold - rank, 0) for rank in df_feature_target_method_ko_selectionscore_ext['score_rank_descending']]\n",
    "    df_feature_target_method_ko_selectionscore_ext['signed_score_rank_top'+str(rank_threshold)] = df_feature_target_method_ko_selectionscore_ext['score_rank_top'+str(rank_threshold)] * df_feature_target_method_ko_selectionscore_ext['score'] / df_feature_target_method_ko_selectionscore_ext['abs_score']\n",
    "\n",
    "    # \n",
    "    df_feature_target_method_ko_selectionscore_ext = pd.merge(df_feature_target_method_ko_selectionscore_ext, df_category_ko, on = 'KO')\n",
    "    df_feature_target_method_ko_selectionscore_ext = df_feature_target_method_ko_selectionscore_ext.fillna(0)\n",
    "    \n",
    "    return df_feature_target_method_ko_selectionscore_ext\n",
    "\n",
    "def make_heatmap_ko_md_rank(df_feature_target_method_ko_selectionscore_ext, category, category_i, rank_threshold, featureset, selection):\n",
    "    \n",
    "        df_feature_target_method_ko_selectionscore_ext_of_a_category = df_feature_target_method_ko_selectionscore_ext[\n",
    "            df_feature_target_method_ko_selectionscore_ext['category'] == category\n",
    "        ]\n",
    "\n",
    "        df_ko_md_toprank = sparsemtx2mtx(df_feature_target_method_ko_selectionscore_ext_of_a_category['KO'], df_feature_target_method_ko_selectionscore_ext_of_a_category['feature'], df_feature_target_method_ko_selectionscore_ext_of_a_category['signed_score_rank_top'+str(rank_threshold)])\n",
    "\n",
    "        df_ko_md_rank       = sparsemtx2mtx(df_feature_target_method_ko_selectionscore_ext_of_a_category['KO'], df_feature_target_method_ko_selectionscore_ext_of_a_category['feature'], df_feature_target_method_ko_selectionscore_ext_of_a_category['score_rank_descending'])\n",
    "\n",
    "        \n",
    "        # To sort columns\n",
    "        df_module_maxcategory_ext = pd.merge(pd.DataFrame(df_ko_md_toprank.columns, columns= ['Module']), df_maxcategory_module).sort_values('category')\n",
    "        # To sort rows\n",
    "        df_ko_md_ext = pd.merge(pd.DataFrame(df_ko_md_toprank.index, columns= ['KO']), df_md_ko).sort_values('Module')\n",
    "        #df_category_pathway_md_ext = pd.merge(df_maxcategory_pathway[df_maxcategory_pathway['category'] == '09111 Xenobiotics biodegradation and metabolism'], df_path_md).sort_values('Module')\n",
    "        #df_ko_path_md_ext = pd.merge(df_ko_md_ext, df_category_pathway_md_ext, on = 'Module').sort_values('Module')\n",
    "        #df_ko_md_ext = df_ko_path_md_ext.sort_values('Module'). sort_values('Pathway', kind = 'mergesort')\n",
    "        i=0\n",
    "        id_list = []\n",
    "        prev_md=\"\"\n",
    "        for md in df_ko_md_ext.Module:\n",
    "            if (prev_md!=md): i+=1\n",
    "            id_list.append((i%2+1)*0.2 )\n",
    "            prev_md=md\n",
    "        df_ko_md_ext['Module_id'] = id_list\n",
    "\n",
    "        # Plot: KO-Module-Rank of feature importance\n",
    "        fig = plt.figure(figsize=(5,3))\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax2 = fig.add_axes([0.95,0.1,0.05, 0.4])\n",
    "        ax3 = fig.add_axes([0.08, 0.1, 0.015, 0.8])\n",
    "        ax4 = fig.add_axes([0.1, 0.05, 0.8, 0.045])\n",
    "        ax5 = fig.add_axes([0.06, 0.1, 0.015, 0.8])\n",
    "\n",
    "        sns.heatmap(df_ko_md_toprank.reindex(\n",
    "            columns = df_module_maxcategory_ext.Module,\n",
    "            index      = df_ko_md_ext.KO,\n",
    "            ),\n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            ax = ax,\n",
    "            cbar_ax = ax2\n",
    "        )\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_title(category)\n",
    "\n",
    "        # Columns\n",
    "        cmap = ListedColormap([cm(i) for i in range(11)], name=\"custom\") # user-defined colormap\n",
    "        sns.heatmap([pd.merge(df_module_maxcategory_ext, df_category_color).category_id], ax = ax4, cbar = False, cmap = cmap)\n",
    "        ax4.tick_params(bottom = False, left = False, labelbottom = False, labelleft = False)\n",
    "        ax4.set_xlabel(\"Predictor: 339 modules in KEGG Module\")\n",
    "\n",
    "        # Rows\n",
    "        sns.heatmap([[i] for i in df_ko_md_ext.Module_id], ax = ax3, cbar = False, cmap = 'binary', vmin=0, vmax=1)\n",
    "        sns.heatmap([[0]], ax = ax5, cbar = False, cmap = ListedColormap([cm(category_i)], name=\"custom\"), vmin=0, vmax=1)\n",
    "        ax5.set_ylabel(\"Predicted OGs\")\n",
    "\n",
    "        ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False, )\n",
    "        ax3.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False, )\n",
    "        ax4.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False, )\n",
    "        ax5.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False, )\n",
    "\n",
    "        plt.savefig(\"figures/NK_M0151_module_ko_importance_\"+featureset+\"_\"+target+\"_\"+selection+\"_top\"+str(rank_threshold)+\"_\"+category+\".pdf\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        #return df_ko_md_toprank\n",
    "        return df_ko_md_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each category, create an overview heatmap\n",
    "for target, rank_threshold, feature_set, selection in [('gain', 14, 'md', 'ANOVA'), ('gain', 50, 'md', 'RandomForest'), ('loss', 8, 'md', 'ANOVA'), ('loss', 14, 'md', 'RandomForest')]:\n",
    "    \n",
    "    df_feature_target_method_ko_selectionscore_ext = make_df_feature_target_method_ko_selectionscore_ext(target, rank_threshold, feature_set, selection)\n",
    "    \n",
    "   \n",
    "\n",
    "    for category_i, category in enumerate(df_category_color.category):\n",
    "\n",
    "        make_heatmap_ko_md_rank(df_feature_target_method_ko_selectionscore_ext, category, category_i, rank_threshold, feature_set, selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, rank_threshold, feature_set, selection = 'gain', 14, 'md', 'ANOVA'\n",
    "\n",
    "## TO DO: ここはallを指定できるようにすべき\n",
    "category, category_i = '09111 Xenobiotics biodegradation and metabolism', 10\n",
    "\n",
    "df_feature_target_method_ko_selectionscore_ext = make_df_feature_target_method_ko_selectionscore_ext(target, rank_threshold, feature_set, selection)\n",
    "df_ko_md_toprank = make_heatmap_ko_md_rank(df_feature_target_method_ko_selectionscore_ext, category, category_i, rank_threshold, feature_set, selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"figures/important_features_heatmap\")\n",
    "except:\n",
    "    None\n",
    "for module_of_interest in df_maxcategory_module[df_maxcategory_module['category'] == category].Module:\n",
    "\n",
    "    ko_list = list(set(df_md_ko[df_md_ko['Module']==module_of_interest].KO) & set (df_ko_md_toprank.index))\n",
    "    df = df_ko_md_toprank.loc[ko_list,:]\n",
    "    df = df.loc[:, (df.sum(axis=0) != 0)]\n",
    "    df = df.loc[:, df.sum().sort_values(ascending = False).index]\n",
    "    \n",
    "    Nrows = len(df.index)\n",
    "    Ncolumns = len(df.columns)\n",
    "    \n",
    "    if (Nrows > 0 and Ncolumns >0):\n",
    "\n",
    "        fig = plt.figure(figsize=(8*Ncolumns/35*1.1,2*Nrows/8))\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        sns.heatmap(df, ax = ax, cmap = 'coolwarm', center = 0)\n",
    "\n",
    "        plt.savefig(\"figures/important_features_heatmap/NK_M0151_\"+feature_set+\"_\"+target+\"_\"+selection+\"_top\"+str(rank_threshold)+\"_\"+module_of_interest+\".pdf\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate pairs of KEGG Modules which share one or more reactions or contains adjacent reactions\n",
    "network_M = nx.read_gml(\"/Users/konnonaoki/Documents/backupped/Research/IwasakiLab/Data/SyntrophyExploration/NK_S0002/Single_Filter_N_CompressedNetwork.gml\")\n",
    "mapping = {module: module.split(\":\")[1] for module in network_M.nodes}\n",
    "network_M = nx.relabel_nodes(network_M, mapping)\n",
    "network_M_Xenobiotics = network_M.subgraph(df_maxcategory_module[df_maxcategory_module['category'] == '09111 Xenobiotics biodegradation and metabolism'].Module)\n",
    "nx.write_gml(network_M_Xenobiotics, \"networks/network_module.xenobiotics.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in network_M_Xenobiotics.edges:\n",
    "    print(edge[0], edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_module_pair = [\n",
    "    [\"M00551\", \"M00543\"],\n",
    "    [\"M00551\", \"M00538\"],\n",
    "    [\"M00551\", \"M00537\"],\n",
    "    [\"M00638\", \"M00534\"],\n",
    "    [\"M00568\", \"M00548\"],\n",
    "    [\"M00568\", \"M00637\"],\n",
    "    [\"M00539\", \"M00419\"],\n",
    "    [\"M00541\", \"M00418\"],\n",
    "    [\"M00569\", \"M00547\"],\n",
    "    [\"M00569\", \"M00548\"],\n",
    "    [\"M00569\", \"M00637\"],\n",
    "    [\"M00569\", \"M00638\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rank_pair = []\n",
    "for pair in list_module_pair:\n",
    "    rank_pair = []\n",
    "    for i, module in enumerate(pair):\n",
    "        module_of_interest = pair[i]\n",
    "        module_of_interest_the_other = pair[abs(1-i)]\n",
    "\n",
    "        ko_list = list(set(df_md_ko[df_md_ko['Module']==module_of_interest].KO) & set (df_ko_md_toprank.index))\n",
    "        df = df_ko_md_toprank.loc[ko_list,:]\n",
    "        #df = df.loc[:, (df.sum(axis=0) != 0)]\n",
    "        df = df.loc[:, df.sum().sort_values(ascending = False).index]\n",
    "        print(i, module, df.mean()[module_of_interest_the_other])\n",
    "        rank_pair.append(df.mean()[module_of_interest_the_other])\n",
    "    list_rank_pair.append(rank_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(list_rank_pair, columns = [\"central\", \"peripheral\"])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax.scatter(df_result['central'], df_result['peripheral'], alpha = 0.5)\n",
    "ax.set_xlim(1,339)\n",
    "ax.set_ylim(1,339)\n",
    "#ax.set_xscale(\"log\")\n",
    "#ax.set_yscale(\"log\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e735269e152434eedfcfab596c1b5bd92dbf01a7c5f35c3224738c65ab1c2b6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('metabo': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
